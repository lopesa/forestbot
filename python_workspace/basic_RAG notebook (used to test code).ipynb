{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pypdf\n",
    "#! pip install langchain\n",
    "#! pip install \"langchain[docarray]\"\n",
    "#! pip install chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../..\")\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    PyPDFLoader(\"../pdf/EdAP 2020_EN.pdf\"),\n",
    "    PyPDFLoader(\"../pdf/SOF book-web-rev3d-hires.pdf\"),\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenu de la page \n",
      "440   |  Les forêts du bassin du Congo\n",
      "BibliographieRoca T, Letouzé E. 2016. La révolution des données est-elle en marche ? Implications pour la statistique \n",
      "publique et la démocratie. Afrique contemporaine. 258(2):95-111.\n",
      "Rosen GE, Smith KF. 2010. Summarizing the evidence on the international trade in illegal wildlife. \n",
      "EcoHealth. 7(1):24-32.\n",
      "RRI (Rights and Resources Initiative). 2017. Securing community land rights : Priorities and Opportunities to \n",
      "advance climate and sustainable development\n",
      "METADATA : {'source': '../pdf/SOF book-web-rev3d-hires.pdf', 'page': 466}\n"
     ]
    }
   ],
   "source": [
    "page = docs[870]\n",
    "print(f\"Contenu de la page \\n{page.page_content[0:500]}\")\n",
    "print(f\"METADATA : {page.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196\n",
      "878\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500, chunk_overlap=50, separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(len(splits))\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed / Vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Embedding and Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "persist_directory = \"../vectorstore/chroma/\"\n",
    "\n",
    "\n",
    "# Delete the persist_directory if you want to force the generatation of another vector store\n",
    "#! rm -rf persist_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new Vectore Store if foler Chroma is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the vector store already exists\n",
    "if os.path.exists(persist_directory):\n",
    "    # If the vector store exists, load it\n",
    "    vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "else:\n",
    "    # If the vector store does not exist, generate it\n",
    "    # Assuming 'splits' is a list of documents already defined elsewhere in your notebook\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=splits, embedding=embedding, persist_directory=persist_directory\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 158, 'source': '../pdf/EdAP 2020_EN.pdf'}\n",
      "{'page': 216, 'source': '../pdf/SOF book-web-rev3d-hires.pdf'}\n",
      "{'page': 387, 'source': '../pdf/EdAP 2020_EN.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# print(vectordb._collection.count())\n",
    "question = \"What is OFAC stand for ?\"\n",
    "answer_docs = vectordb.similarity_search(question, k=3)\n",
    "len(answer_docs)\n",
    "answer_docs[0].page_content\n",
    "for d in answer_docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMR search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 158, 'source': '../pdf/EdAP 2020_EN.pdf'}\n",
      "{'page': 387, 'source': '../pdf/EdAP 2020_EN.pdf'}\n"
     ]
    }
   ],
   "source": [
    "answer_docs = vectordb.max_marginal_relevance_search(question, k=2, fetch_k=3)\n",
    "len(answer_docs)\n",
    "answer_docs[0].page_content\n",
    "for d in answer_docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter on SOF (State of forest) only (doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of EdAP 2020_EN.pdf or SOF book-web-rev3d-hires.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the document\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Report of forest and protected area\"\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, vectordb, document_content_description, metadata_field_info, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "question = \"what OFAC stand for, check answer in SOF document\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compression of retrieved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillaume/.local/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/guillaume/.local/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/guillaume/.local/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/guillaume/.local/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "OFAC and COMIFAC\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- COMIFAC\n",
      "- Central Africa\n",
      "- sustainable and coordinated management of forest ecosystems\n",
      "- orientation, harmonization and monitoring of forestry and environmental policies\n",
      "- emerged from the commitments made in March 1999 by the Heads of State of Central Africa in the “Yaoundé Declaration”\n",
      "- ten member countries of the subregion\n",
      "- common natural heritage\n",
      "- legal framework governed by the February 2005 treaty: “Treaty on the Conservation and Sustainable Management of Forest Ecosystems in Central Africa and to establish the Central African Forests Commission”\n",
      "- Convergence Plan defines the shared ten-year intervention strategies of Central African States and development partners in the field of conservation and sustainable management of forest and savanna ecosystems\n",
      "- second edition of this plan, covering the period 2015-2025\n",
      "- Web site: www.comifac.org\n",
      "- OFAC: Central Africa Forest Observatory\n",
      "- specialised unit of COMIFAC\n",
      "- coordinating the Forest Observatory\n",
      "- COMIFAC National Coordination committees\n",
      "- collaboration with all of the partners producing and disseminating information on the forests and ecosystems of Central Africa\n",
      "- responsible for coordinating the collection and editing of data, the analysis of results and the dissemination of information\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "OFAC: OFAC thus provides the subregion and its partners with essential tools for steering and sharing knowledge for better governance and sustainable management of forest ecosystems. The unit contributes to the organization and dissemination of information within the Congo Basin Forest Partnership (CBFP). It benefits from a support project financed by the European Union and the BIOPAMA program (IUCN and JRC).\n",
      "COMIFAC: OFAC-COMIFAC & IUCN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "- L’OFAC effectue déjà un travail de compilation des informations pour alimenter le suivi de la mise en oeuvre du Plan de convergence de la COMIFAC.\n",
      "- Il serait utile de renforcer les capacités de cette Cellule pour qu’elle soit en mesure de traiter des données sur les ODD, en plus des données collectées par les pays pour renseigner les indicateurs du Plan de convergence de la COMIFAC qu’elle traite déjà actuellement.\n"
     ]
    }
   ],
   "source": [
    "# Guillaume comment :\n",
    "# In this section, we will use a Langchain compressor to reduce the amount of text retrieve.\n",
    "# By doing this, the summarized text produced is almost an answer\n",
    "\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Wrap our vectorstore\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=vectordb.as_retriever()\n",
    ")\n",
    "\n",
    "question = \"what is the difference between OFAC and COMIFAC?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff technics : all document are sent to the LLM to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are creating a answer chain with Langchain. We make a specific prompt.\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OFAC is a specialized unit of COMIFAC responsible for coordinating the Forest Observatory and disseminating information on Central Africa's forests and ecosystems. COMIFAC, on the other hand, is an organization responsible for harmonizing and monitoring forestry and environmental policies in Central Africa. Thanks for asking!\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the difference between OFAC and COMIFAC?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map reduce : it combine all retrieved data before sending to the LLM to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OFAC's main expertise is in collecting and managing environmental data in Central Africa to support the sustainable management of forest ecosystems. It contributes to reducing deforestation by providing essential tools for steering and sharing knowledge for better governance and sustainable management of forest ecosystems in the region. Thanks for asking!\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm, retriever=vectordb.as_retriever(), chain_type=\"map_reduce\"\n",
    ")\n",
    "question = (\n",
    "    \"What is the main expertise of OFAC ? How it contribute to reduce deforestation ?\"\n",
    ")\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refine : it improve the answer with each different document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OFAC's main expertise is in collecting and managing environmental data in Central Africa to support the sustainable management of forest ecosystems. It contributes to reducing deforestation by providing essential tools for steering and sharing knowledge for better governance and sustainable management of forest ecosystems in the region. Thanks for asking!\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm, retriever=vectordb.as_retriever(), chain_type=\"refine\"\n",
    ")\n",
    "question = (\n",
    "    \"What is the main expertise of OFAC ? How it contribute to reduce deforestation ?\"\n",
    ")\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q/A with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)\n",
    "\n",
    "question = (\n",
    "    \"What is the main expertise of OFAC ? How it contribute to reduce deforestation ?\"\n",
    ")\n",
    "result = qa.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main expertise of OFAC (Central Africa Forest Observatory) lies in ensuring the availability of information to support the sustainable management of forest ecosystems in Central Africa. OFAC contributes to reducing deforestation by collecting and managing environmental data at different scales, conducting annual campaigns to collect reference data in its member states, and collaborating with various partners to harmonize and disseminate information. Additionally, OFAC plays a crucial role in promoting knowledge transfer and skills between countries and actors, ultimately providing essential tools for steering and sharing knowledge for better governance and sustainable management of forest ecosystems in the region.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OFAC and COMIFAC are both mentioned in the provided context, but the text does not explicitly outline the specific differences between the two entities. The text describes OFAC as playing a role in data storage, analysis, and transmission to support decision-making within the reach of managers, while COMIFAC is mentioned in the context of a Council of Ministers and holders of global issues. For more detailed differences between OFAC and COMIFAC, further information or sources specific to these organizations would be needed.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Which difference with COMIFAC ?\"  # Check if it understand it's difference between OFAC and COMIFAC\n",
    "result = qa.invoke({\"question\": question})\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with memory (doesn't work!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import panel as pn\n",
    "# import param\n",
    "\n",
    "\n",
    "# class cbfs(param.Parameterized):\n",
    "#     chat_history = param.List([])\n",
    "#     answer = param.String(\"\")\n",
    "#     db_query = param.String(\"\")\n",
    "#     db_response = param.List([])\n",
    "\n",
    "#     def __init__(self, **params):\n",
    "#         super(cbfs, self).__init__(**params)\n",
    "#         self.panels = []\n",
    "#         self.loaded_file = \"../pdf/SOF book-web-rev3d-hires.pdf\"\n",
    "#         self.qa = load_db(self.loaded_file, \"stuff\", 4)\n",
    "\n",
    "#     def call_load_db(self, count):\n",
    "#         if count == 0 or file_input.value is None:  # init or no file specified :\n",
    "#             return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "#         else:\n",
    "#             file_input.save(\"temp.pdf\")  # local copy\n",
    "#             self.loaded_file = file_input.filename\n",
    "#             button_load.button_style = \"outline\"\n",
    "#             self.qa = load_db(\"temp.pdf\", \"stuff\", 4)\n",
    "#             button_load.button_style = \"solid\"\n",
    "#         self.clr_history()\n",
    "#         return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "\n",
    "#     def convchain(self, query):\n",
    "#         if not query:\n",
    "#             return pn.WidgetBox(\n",
    "#                 pn.Row(\"User:\", pn.pane.Markdown(\"\", width=600)), scroll=True\n",
    "#             )\n",
    "#         result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
    "#         self.chat_history.extend([(query, result[\"answer\"])])\n",
    "#         self.db_query = result[\"generated_question\"]\n",
    "#         self.db_response = result[\"source_documents\"]\n",
    "#         self.answer = result[\"answer\"]\n",
    "#         self.panels.extend(\n",
    "#             [\n",
    "#                 pn.Row(\"User:\", pn.pane.Markdown(query, width=600)),\n",
    "#                 pn.Row(\n",
    "#                     \"ChatBot:\",\n",
    "#                     pn.pane.Markdown(\n",
    "#                         self.answer, width=600, style={\"background-color\": \"#F6F6F6\"}\n",
    "#                     ),\n",
    "#                 ),\n",
    "#             ]\n",
    "#         )\n",
    "#         inp.value = \"\"  # clears loading indicator when cleared\n",
    "#         return pn.WidgetBox(*self.panels, scroll=True)\n",
    "\n",
    "#     @param.depends(\n",
    "#         \"db_query \",\n",
    "#     )\n",
    "#     def get_lquest(self):\n",
    "#         if not self.db_query:\n",
    "#             return pn.Column(\n",
    "#                 pn.Row(\n",
    "#                     pn.pane.Markdown(\n",
    "#                         \"Last question to DB:\", styles={\"background-color\": \"#F6F6F6\"}\n",
    "#                     )\n",
    "#                 ),\n",
    "#                 pn.Row(pn.pane.Str(\"no DB accesses so far\")),\n",
    "#             )\n",
    "#         return pn.Column(\n",
    "#             pn.Row(\n",
    "#                 pn.pane.Markdown(\"DB query:\", styles={\"background-color\": \"#F6F6F6\"})\n",
    "#             ),\n",
    "#             pn.pane.Str(self.db_query),\n",
    "#         )\n",
    "\n",
    "#     @param.depends(\n",
    "#         \"db_response\",\n",
    "#     )\n",
    "#     def get_sources(self):\n",
    "#         if not self.db_response:\n",
    "#             return\n",
    "#         rlist = [\n",
    "#             pn.Row(\n",
    "#                 pn.pane.Markdown(\n",
    "#                     \"Result of DB lookup:\", styles={\"background-color\": \"#F6F6F6\"}\n",
    "#                 )\n",
    "#             )\n",
    "#         ]\n",
    "#         for doc in self.db_response:\n",
    "#             rlist.append(pn.Row(pn.pane.Str(doc)))\n",
    "#         return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "#     @param.depends(\"convchain\", \"clr_history\")\n",
    "#     def get_chats(self):\n",
    "#         if not self.chat_history:\n",
    "#             return pn.WidgetBox(\n",
    "#                 pn.Row(pn.pane.Str(\"No History Yet\")), width=600, scroll=True\n",
    "#             )\n",
    "#         rlist = [\n",
    "#             pn.Row(\n",
    "#                 pn.pane.Markdown(\n",
    "#                     \"Current Chat History variable\",\n",
    "#                     styles={\"background-color\": \"#F6F6F6\"},\n",
    "#                 )\n",
    "#             )\n",
    "#         ]\n",
    "#         for exchange in self.chat_history:\n",
    "#             rlist.append(pn.Row(pn.pane.Str(exchange)))\n",
    "#         return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "#     def clr_history(self, count=0):\n",
    "#         self.chat_history = []\n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import docarray python package. Please install it with `pip install \"langchain[docarray]\"`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/langchain_community/vectorstores/docarray/base.py:19\u001b[0m, in \u001b[0;36m_check_docarray_import\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdocarray\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     da_version \u001b[38;5;241m=\u001b[39m docarray\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/docarray/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocList, DocVec\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_doc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDoc\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/docarray/array/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01many_array\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnyDocArray\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc_list\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc_list\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocList\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/docarray/array/any_array.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_doc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDoc\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_array_summary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocArraySummary\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/docarray/base_doc/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_doc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01many_doc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnyDoc\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_doc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_node\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseNode\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/docarray/base_doc/any_doc.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Type\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDoc\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAnyDoc\u001b[39;00m(BaseDoc):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/docarray/base_doc/doc.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ROOT_KEY\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrich\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconsole\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Console\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ROOT_KEY' from 'pydantic.main' (/home/guillaume/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/pydantic/main.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cb \u001b[38;5;241m=\u001b[39m \u001b[43mcbfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m file_input \u001b[38;5;241m=\u001b[39m pn\u001b[38;5;241m.\u001b[39mwidgets\u001b[38;5;241m.\u001b[39mFileInput(accept\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m button_load \u001b[38;5;241m=\u001b[39m pn\u001b[38;5;241m.\u001b[39mwidgets\u001b[38;5;241m.\u001b[39mButton(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad DB\u001b[39m\u001b[38;5;124m\"\u001b[39m, button_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprimary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mcbfs.__init__\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpanels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../pdf/SOF book-web-rev3d-hires.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqa \u001b[38;5;241m=\u001b[39m \u001b[43mload_db\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_file\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstuff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36mload_db\u001b[0;34m(file, chain_type, k)\u001b[0m\n\u001b[1;32m      9\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# create vector database from data\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mDocArrayInMemorySearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# define retriever\u001b[39;00m\n\u001b[1;32m     13\u001b[0m retriever \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mas_retriever(search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m, search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: k})\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/langchain_core/vectorstores.py:550\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    549\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/langchain_community/vectorstores/docarray/in_memory.py:68\u001b[0m, in \u001b[0;36mDocArrayInMemorySearch.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     53\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DocArrayInMemorySearch:\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an DocArrayInMemorySearch store and insert data.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m        DocArrayInMemorySearch Vector Store\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     store\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m store\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/langchain_community/vectorstores/docarray/in_memory.py:39\u001b[0m, in \u001b[0;36mDocArrayInMemorySearch.from_params\u001b[0;34m(cls, embedding, metric, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_params\u001b[39m(\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     29\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DocArrayInMemorySearch:\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize DocArrayInMemorySearch store.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m        **kwargs: Other keyword arguments to be passed to the get_doc_cls method.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     \u001b[43m_check_docarray_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InMemoryExactNNIndex\n\u001b[1;32m     42\u001b[0m     doc_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_doc_cls(space\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/langchain_community/vectorstores/docarray/base.py:29\u001b[0m, in \u001b[0;36m_check_docarray_import\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use the DocArrayHnswSearch VectorStore the docarray \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion >=0.32.0 is expected, received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocarray\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo upgrade, please run: `pip install -U docarray`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m         )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import docarray python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease install it with `pip install \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain[docarray]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     32\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import docarray python package. Please install it with `pip install \"langchain[docarray]\"`."
     ]
    }
   ],
   "source": [
    "# cb = cbfs()\n",
    "\n",
    "# file_input = pn.widgets.FileInput(accept=\".pdf\")\n",
    "# button_load = pn.widgets.Button(name=\"Load DB\", button_type=\"primary\")\n",
    "# button_clearhistory = pn.widgets.Button(name=\"Clear History\", button_type=\"warning\")\n",
    "# button_clearhistory.on_click(cb.clr_history)\n",
    "# inp = pn.widgets.TextInput(placeholder=\"Enter text here…\")\n",
    "\n",
    "# bound_button_load = pn.bind(cb.call_load_db, button_load.param.clicks)\n",
    "# conversation = pn.bind(cb.convchain, inp)\n",
    "\n",
    "# jpg_pane = pn.pane.Image(\"./img/convchain.jpg\")\n",
    "\n",
    "# tab1 = pn.Column(\n",
    "#     pn.Row(inp),\n",
    "#     pn.layout.Divider(),\n",
    "#     pn.panel(conversation, loading_indicator=True, height=300),\n",
    "#     pn.layout.Divider(),\n",
    "# )\n",
    "# tab2 = pn.Column(\n",
    "#     pn.panel(cb.get_lquest),\n",
    "#     pn.layout.Divider(),\n",
    "#     pn.panel(cb.get_sources),\n",
    "# )\n",
    "# tab3 = pn.Column(\n",
    "#     pn.panel(cb.get_chats),\n",
    "#     pn.layout.Divider(),\n",
    "# )\n",
    "# tab4 = pn.Column(\n",
    "#     pn.Row(file_input, button_load, bound_button_load),\n",
    "#     pn.Row(\n",
    "#         button_clearhistory,\n",
    "#         pn.pane.Markdown(\"Clears chat history. Can use to start a new topic\"),\n",
    "#     ),\n",
    "#     pn.layout.Divider(),\n",
    "#     pn.Row(jpg_pane.clone(width=400)),\n",
    "# )\n",
    "# dashboard = pn.Column(\n",
    "#     pn.Row(pn.pane.Markdown(\"# ChatWithYourData_Bot\")),\n",
    "#     pn.Tabs(\n",
    "#         (\"Conversation\", tab1),\n",
    "#         (\"Database\", tab2),\n",
    "#         (\"Chat History\", tab3),\n",
    "#         (\"Configure\", tab4),\n",
    "#     ),\n",
    "# )\n",
    "# dashboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
