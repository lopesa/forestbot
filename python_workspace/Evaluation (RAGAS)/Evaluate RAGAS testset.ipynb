{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial :\n",
    "https://docs.ragas.io/en/stable/getstarted/evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "from Call_RAG import ask\n",
    "from datasets import Dataset\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "env_path = find_dotenv()\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_testset = pd.read_csv(\"evaluation_dataset.csv\")\n",
    "df_testset = pd.read_csv(\"evaluation_dataset_LLAMA3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add answer column from RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter une colonne 'answer' en initialisant avec des chaînes vides ou NaN\n",
    "df_testset[\"answer\"] = pd.NA\n",
    "\n",
    "# Générer la réponse pour chaque question et la stocker dans la colonne 'answer'\n",
    "for index, row in df_testset.iterrows():\n",
    "    user_input = row[\"question\"]  # Assurez-vous que la colonne s'appelle 'question'\n",
    "    output = ask(user_input)\n",
    "    df_testset.at[index, \"answer\"] = output\n",
    "\n",
    "df_testset.to_csv(\"evaluation_dataset for RAG1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform df_testset into dictionnary then into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowTypeError",
     "evalue": "Expected bytes, got a 'float' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[1;32m      3\u001b[0m Dictionnary_from_dataset \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: df_testset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: df_testset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m\"\u001b[39m: df_testset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m     10\u001b[0m }\n\u001b[0;32m---> 12\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDictionnary_from_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/datasets/arrow_dataset.py:963\u001b[0m, in \u001b[0;36mDataset.from_dict\u001b[0;34m(cls, mapping, features, info, split)\u001b[0m\n\u001b[1;32m    961\u001b[0m     arrow_typed_mapping[col] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    962\u001b[0m mapping \u001b[38;5;241m=\u001b[39m arrow_typed_mapping\n\u001b[0;32m--> 963\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/datasets/table.py:758\u001b[0m, in \u001b[0;36mInMemoryTable.from_pydict\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pydict\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    744\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;124;03m    Construct a Table from Arrow arrays or columns.\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;124;03m        `datasets.table.Table`\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/pyarrow/table.pxi:1920\u001b[0m, in \u001b[0;36mpyarrow.lib._Tabular.from_pydict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/pyarrow/table.pxi:5992\u001b[0m, in \u001b[0;36mpyarrow.lib._from_pydict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/pyarrow/array.pxi:385\u001b[0m, in \u001b[0;36mpyarrow.lib.asarray\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/pyarrow/array.pxi:247\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/pyarrow/array.pxi:112\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/datasets/arrow_writer.py:193\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     trying_cast_to_python_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# use smaller integer precisions if possible\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrying_int_optimization:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/pyarrow/array.pxi:355\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/pyarrow/array.pxi:42\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/forestbot-QnTDFiWY-py3.10/lib/python3.10/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: Expected bytes, got a 'float' object"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "\n",
    "Dictionnary_from_dataset = {\n",
    "    \"question\": df_testset[\"question\"].tolist(),\n",
    "    \"answer\": df_testset[\"answer\"].tolist(),\n",
    "    \"contexts\": df_testset[\"contexts\"]\n",
    "    .apply(lambda x: x.split(\",\"))\n",
    "    .tolist(),  # Chaque contexte est une liste de chaînes\n",
    "    \"ground_truth\": df_testset[\"ground_truth\"].tolist(),\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(Dictionnary_from_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f923364878264698b740eecd17616fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = evaluate(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display result of the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do the Aichi Targets promote coordinated a...</td>\n",
       "      <td>The Aichi Targets promote coordinated actions ...</td>\n",
       "      <td>[[' are promoted through the Aichi Targets. Th...</td>\n",
       "      <td>The Aichi Targets promote coordinated actions ...</td>\n",
       "      <td>0.928637</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the purpose of the Observatory of Biod...</td>\n",
       "      <td>The purpose of the Observatory of Biodiversity...</td>\n",
       "      <td>[['MINFOF: Ministère des Forêts et de la Faune...</td>\n",
       "      <td>The purpose of the Observatory of Biodiversity...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do protected areas in Central African coun...</td>\n",
       "      <td>Protected areas in Central African countries c...</td>\n",
       "      <td>[['40\\nVarious COMIFAC directives,  notably th...</td>\n",
       "      <td>Protected areas in Central African countries c...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does habitat destruction pose a threat to ...</td>\n",
       "      <td>Habitat destruction in Central Africa leads to...</td>\n",
       "      <td>[['32\\n2.2. Rich but threatened  \\nanimal dive...</td>\n",
       "      <td>Habitat destruction poses a threat to great ap...</td>\n",
       "      <td>0.921716</td>\n",
       "      <td>0.863277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What were the broad objectives for the overhau...</td>\n",
       "      <td>The broad objectives for the overhaul of the C...</td>\n",
       "      <td>[['42\\nand to clarify its positioning in the n...</td>\n",
       "      <td>The broad objectives for the overhaul of UTOs ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923989</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How do the Aichi Targets promote coordinated a...   \n",
       "1  What is the purpose of the Observatory of Biod...   \n",
       "2  How do protected areas in Central African coun...   \n",
       "3  How does habitat destruction pose a threat to ...   \n",
       "4  What were the broad objectives for the overhau...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The Aichi Targets promote coordinated actions ...   \n",
       "1  The purpose of the Observatory of Biodiversity...   \n",
       "2  Protected areas in Central African countries c...   \n",
       "3  Habitat destruction in Central Africa leads to...   \n",
       "4  The broad objectives for the overhaul of the C...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [[' are promoted through the Aichi Targets. Th...   \n",
       "1  [['MINFOF: Ministère des Forêts et de la Faune...   \n",
       "2  [['40\\nVarious COMIFAC directives,  notably th...   \n",
       "3  [['32\\n2.2. Rich but threatened  \\nanimal dive...   \n",
       "4  [['42\\nand to clarify its positioning in the n...   \n",
       "\n",
       "                                        ground_truth  answer_relevancy  \\\n",
       "0  The Aichi Targets promote coordinated actions ...          0.928637   \n",
       "1  The purpose of the Observatory of Biodiversity...          1.000000   \n",
       "2  Protected areas in Central African countries c...          1.000000   \n",
       "3  Habitat destruction poses a threat to great ap...          0.921716   \n",
       "4  The broad objectives for the overhaul of UTOs ...          1.000000   \n",
       "\n",
       "   context_precision  faithfulness  context_recall  \n",
       "0           1.000000           0.4             1.0  \n",
       "1           1.000000           1.0             1.0  \n",
       "2           0.849645           1.0             1.0  \n",
       "3           0.863277           1.0             1.0  \n",
       "4           0.923989           0.5             1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = result.to_pandas()\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forestbot-QnTDFiWY-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
